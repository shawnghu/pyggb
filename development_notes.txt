where i am now:
[x] just solved a problem with the generator throwing in the middle of commands, causing incorrect stuff to be reconstructed
[x] need to solve discriminator still throws errors due to keyerror due to sometimes ill-constructed command files
    [x] solved

(should have done some unit testing?)
(more like instead of writing tests, should just make more atomic changes)
(also should do things more breadth-first)


cursor hotkeys:
    - bash: ctrl-y to paste. ctrl-/ to under
    - focus chat hotkey? ctrl-y taken by bash
vim keys:
    - see :help g
    - ge to get to end of previous word
    - gi to edit at last edit position
    - what is visualstar?
    - https://filiphalas.com/keyboard-controlled-vscode-with-vim-and-tmux
        - see tmux, sneak, etc. settings, substitution, surround
    - C-d now does something weird ('visual multi-cursor') that doesn't work with a correctly

- fixed translation errors:
    - arg order in mirror commands
    - unhandled triangle retvals for the new segments

- create simple script to analyze problem output distribution
- grade problems by the 100s to see output difficulty distribution
- visualize problems

- high level agenda:
- fix (some of) the dumb things
[x] do restricted problem generation
- fix dumb things in iteration if needed
    [x] ban making more than one point that is just floating
    [x] ban making point at fixed distance from another point after too long
- add more commands(?)
    - build triangle by fiat (return the points)
        - equilateral triangle
        - triangle with fixed lengths
        - triangle with fixed angle measures
            - too hard
    - circle chords
        - chord of fixed length
        - chord orthogonal to existing line
    - internally tangent circle
    - externally tangent circle
    - circle tangent to two others? (has the problem of always returning two circles if they are externally tangent. but can do a randomizer.)
    - triangle area


list of dumb things:
- point_at_distance_along_line actually is very important, so we need to fix its ambiguity


- sometimes things only rely in any meaningful way on something constructed way down the line
- note most functions only return one point, so this point should be meaningful in some way to the rest of the problem beforehand.
- functions which only take one input are possibly pretty bad?

- we can restore the degenerate point logic in the command sampling. 

- and then, fix the translations so they're less ugly.


aime questions are all in the passive voice, and do use stuff like "Let" or simply assert the existence of stuff from the jump.


[d] generalize the parameterization logic for the exploratory geometry constructor.
    [d] see if all reasonable generators are actually just variants of the main one by params.
[x] move all the stuff into a single pipeline script
- and integrate with yiyou's repo
    [d] refactor the pipeline so that knowledge is carried forward. in particular, commands can easily be graded at construction time, and also translated directly from Command object. (Great opportunity for Cursor composer.)
        - this also is not actually needed. in particular, there is no benefit from abstracting out measure_test.py.
        [x] But the Construction parser can indeed be used for the translator, to derive types for everything. (Made the logic for translator incredibly simpler)
- improve the wording of problems to be more like AIME problems
    [x] read some AIME problems to get a sense of these
    - heuristics for operating on lines
    [x] rewording individual commands (particularly construction of individual points)

[x] reduce the frequency of construction of polygons.

[x] special case constructions of polygons and triangles in translation (handled automatically by ident logic)
    [x] simply ban polygon construction more than once
    [x] polygons are constructed at a fixed angle relative to the axes, which is a mistranslation. rotate polygon by a random amount.
    [x] the same general concept means functions that return more than one output have been banned
    [x] need to fix big random float angles

- improve problem quality:
    - look at the distribution of sampled commands more closely. some problems seem to be somewhat degenerate


- vim matters:
- ctrl-i, ctrl-w, ctrl-n clash pretty badly with things i often want to do (composer, close window)
    - :q closes window just fine
- does typing with vim keybinds actually make me noticeably faster?
- if so, it's worth it to invest in
- if not, fuck it


- guiding principle for design: try to make this thing a tool that actually is useful for generating geometry problems. maybe is useful in itself.

(other datasets may be easier of or lower quality)

- develop "problem categories": (note here the emphasis on being able to perform "controlled" FT experiments)
    - triangles and related
    - circles and related
    - lines and points and intersections and orthogonals
    - other? polygons?
    - other other?
    - "coordinate"?

- solve my vimrc problem
- solve my left/right arrow key problem, more specifically

- evaluate problem difficulty distribution better
    - (just use the grader)
    - build better automated tools

- design a "compositional" geometry + "algebra" problem.
    - note the design constraints: 
    - the decomposition into two "subproblems" must be clear.
    - ideally, should make use of our existing capabilities to some extent...

- split exploratory geometry problems into categories for construction
- build the new geometry "visualization" problem dataset

- help design number theory problems/training set
    - a product of three primes property?



thinking out loud here:
- the thing is potentially useful to others, and impressive in itself
so we want to extend it to be general-purpose
- so we want to define a language to describe all the things you may want to specify in the constructions.
- not doing this is tantamount to asking the user to read the code and modify it themselves.
- but most importantly, I think we don't need to do this right now, particularly since it doesn't seem like there are very good solutions.

- uh, how are we gonna know if the distribution of questions is any good again?

think of uses for deep research and etc.




- note construction.render() function for visualizing the polygon intersection problems, later

- later answer what yiyou wondered about whether o4 or r1 breaks first on these long problems


--REMEMBER to evaluate openthinker. it doesn't seem much better than qwen. 

- can improve feedback times on inference for small datasets by keeping a model loaded in memory using vllm server
    - vllm serve "open-thoughts/OpenThinker-32B" --tensor-parallel-size=1 --disable-log-requests --enable-chunked-prefill --enable-prefix-caching

- generally improve sampling heuristics, as needed, for variety.
- would be good if we could somehow construct the set of points satisfying a predicate. but that seems quite advanced and somewhat out of the reach of this project...

## compositional problems
- need to make sure that the model can't solve the test questions.

-geo-arith problem: construct a regular polygon. set an arithmetic condition on when to draw lines between points
-subproblems: determine when the arithmetic condition holds. determine what the result of drawing the lines is:

-subproblems: be generally good at combinatorics / counting intersections and shit. be better at geometry in the sense that we know how to handle rotations and shit.

**************************************************************88
Work log pre-20250505
**************************************************************
list of dumb things:
[x] solve ident stuff (too many idents)
[x] lines could be constructed on top of each other, points, circles
[x] segment of fixed length is constructed, circle constructed with that as radius, we ask for the radius of the circle instead of just the length of the segment
    [x] now circles can't be constructed with segment, only by two points, three points, or radius directly
    [x] it's still possible to do dumb things like construct a circle with two points then ask for the radius, which is just the same as asking for the dist between the points. (filter constructions by conditions on the measured variable)
[x] likewise, it's possible to construct two points at a fixed distance and then just ask for the distance between those two points, which is kind of dumb.
    [x] note fundamentally there are only like three kinds of measures: distance, angle, area (special triangle ops like circumradius, inradius). and area is not really possible for anything other than a triangle because areas of regular polygons are boring and irregular polygons can't be reliably constructed. 
        [x] handled in translator measure type
        - it will be good to add "ratio".
            - will not do. too hard for too little reward
    [x] special casing for regular polygon translation

translations:
[x] a point constructed at a fixed distance from another point is just called a segment, so do that
    -instead of "A point G is placed so that it is 5 units away from point N in any direction." maybe  just "G is constructed so that NG = 5". Even worse if N was not constructed by important means, then it's just "NG = 5".

- distribution of problems. Triangles can be constructed more easily. Somehow still too many polygons are constructed


**************************************************************88
Work log pre-20250430
**************************************************************
        -TO DERISK, GET TO READING SOME TRANSLATED PROBLEMS ASAP.
        - you can operationalize the structure by trying to write some problems by hand
        [x] initial behavior is quite simple: simply start by constructing a polygon, and soon thereafter invoke a rotation on the polygon.
        - tricky thing: should the rest of the diagram rotate as well? naturally, not, but then what is the nature of the relation to the original polygon, i.e, how do we ask about rotation?
        - maybe you want to refer to the original polygon's vertices, maybe sometimes you also want to refer to the "rotated" polygon's vertices. 
            [x] best trick for this is by making the idents variations on the originals, i.e, H gets rotated to H'.
            [x] also, sample sequential idents specifically for the polygon 80% of the time.
        [x] remember to sample interesting angles more often. override sample polygon sides or whatever it is, also
        - determine whether it makes sense to do axis-alignment / specify absolute slopes/orientation. i think probably not, in a pure sense.

- general critique: by tuning the difficulty of the problem we can appear to achieve a result, assuming the fine tuning helps at all and the difficulty is approximately projected onto one dimension.
if composition is an entirely separate matter from capability at the subproblems then fine.
    - resolution: problems actually need to broken into "hierarchy of problems" of increasing difficulty, so you know model capabilities and can measure it somehow.



**************************************************************88
Work log 20250425
**************************************************************
[x] why is openthinker so fricken slow? it actually creates problems for the pipeline
    - low hanging fruit: use_cache=False by default.
    - after that, no improvement seems possible; likely it is slower because the reasoning means a larger attention.
        - validated: token return speed is many, many times faster on shorter context, indicating that it's just the long attention calculations
        - trying to get around this: vllm has feature to batch preloads alongside decodes, which i thought would at least make use of the extra capacity when decodes get long, but the effect of this is basically negligible because the long decode compute times dominate completely.
    - re: trying to get the attention itself to run faster:
        - flashinfer is slower, even with other patches i found including FLASHINFER_FORCE_TENSOR_CORES which also does prebuilt kernels 
        - vllm docs say that pagedattention is used automatically, and also instrumentation automatically calculates the best attention backend for everything, so likely there is no fruit here
        - flash attention 3 is built into vllm main lib, based on looking at git and grepping the project for flash attention 3 implementation details
            - also already maximizes throughput for h100s and uses fp8 quantization whereever appropriate, so nothing to squeeze out there either?


**************************************************************88
Work log 20250425-2 (missing lots of debug logs... tired)
**************************************************************
stuck debugging:
[x] fix somehow making it to the end of all commands without sampling successfully (due to erroneous break in diagonal_p special logic)
[x] fix somehow getting stuck in infinite loop on rare occasion (due to chord construction infinite looping on degenerate circles; remove degen circle constructions)
[x] cannot reassign idents after polyogn is constructed, fixed: due to reusing const elements and the data field getting modified during polygon construction time
[x] polygons seem to be constructed at unreasonably high rates: not a bug, just higher than thought
[x] diagonal construction errors: could not map polygon to its vertices due to type error (polygon element vs polygon). type error in diagonal construction (segment_pp vs Segment constructor).

[x] type error in area_P
[x] insidious error affecting construction of polygons-- polygons would never make it because formed program was not semantically valid because number of sides changed due to sampling logic

[x] multithread the generator and the measure_test script
# 4, 7, 15. 30, 35, 48, 75, 94

-remember to check in translations:
    [x] angles/triangles/segments are not named
    [x] polygon vertices are used / polygons are involved in things other than simply the measure of their area
    [x] random_diagonal_p arise, and have sensible translations and the resulting points are actually used
    - rotate polygon_about_center is used sensibly

- handle
    [x] implement rotation around a vertex of a polygon, rotation around the center of a polygon.
    [x] implement constant generation logic for angle measures.
    [x] make a new constructor that overrides sample_command to start with.
**************************************************************88
Work log 20250424
**************************************************************
mechanical translator:

- now there are a couple of errors:
[x] polygons can be made with less than 3 sides i think
    [x] also improve polygon sampling generally
[x] some repetition of the word "segment", maybe "angle".
[x] angles should be specified to be measured in radians.

[x] also, reassign the idents, 'cause the existing problems are ass
[x] add specs to the generated problem jsons.
[x] encourage polygon_ppi() (this one is kind of tricky, maybe it shouldn't be done; maybe it should only happen towards the beginning)
[x] implement more commands: for triangles, to construct polygon from center with circumradius/vertex distance. polygon_ppi seems just to really not work.

fix the problem generator more:
- see what is up with all the probably-hard questions
- sample problems with o4 with a normal validation setup, and see what the approval rate is; 
- more robustly, it is probably possible to cross reference failed questions with the likeliest commands to cause failures, to find bugs in the commands. probably do that
**************************************************************88
Work log 20250423
**************************************************************

[x] create first draft (thankfully this was easy because i factored translate_to_nl really well in the first place)
- finish generating the basic dataset
	[x] prereq to everything: the classical generator problem
	- hardcode translator
		[x] handle const command constructions specially
	    [x] handle polygon command constructions specially
		[x] handle measure commands specially
		[x] check every single fucking command for syntactic correctness
			[x] check to see all the commands are there (polygon I think is not)
			[x] setup a split so that the process can be pipelined (find an example of command, look at command.py, look at translation)
        [x] bonus: improve wording of several specific constructions
		- bonus: do rewordings (and go through these manually, also)
- finish generating the non-basic dataset #1

[x] area takes variable inputs
[x] polygon takes variable inputs
[x] polygon_ppi has variable outputs
**************************************************************88
GRAVEYARD 20250423 (work prior to this date)
**************************************************************
[x] type annotate commands.py


objective is to make constructions randomly.
but pure randomness probably won't work.
[x] for starters, names for symbols should definitely not be random.
[x] secondly, it seems possible to automatically fit the syntax of the commands.
[x]thirdly, it seems like it should be possible to even make the commands type safe, ie, we can pick a command, we can look at the types of the arguments, and we can pick an argument from a list of options.

without worrying about the MC sampling part right now, assuming all the functions get correctly type annotated:
for each command get in code the types that it takes and then the types that it returns. 
for certain commands like poly, may need to do some annoying stuff like add extra args to construct a polygon.
also need to define a specific behavior for ints... 

a little heuristic needs to be done, also, maybe to see how things start, and/or to prune unused commands from files.
more generally, maybe ways needed to bias the sorts of commands that get called, so that the resulting commands are sensible. but maybe type checking will automatically do enough of this.
i think probably randomly constructing several ints and then pruning all the unused ints is going to work.
that, or, at this point since we're writing code, just redo the language so that int and float literals are possible.
defining the behavior of some commands with float literals might turn out to be annoying...

de-risk this by writing the original program generator with only a small set of commands, such as the ones used in some example files.

moreover, it seems like we should be able to do some sort of tree thing where we monte carlo sample to grow the construction tree,
maybe saving time in sampling if it takes too long to sample good constructions when the logic grows

some points of annoyance:
[x] need to also impose the constraint that different args are different identifiers, unless it's appropriate for them to be the same (check manually).
  [x] note i checked, i don't think it is ever very sensible to have the same identifier used for two different arguments in the same command.
[x] need to make sure that the measure command is always the last command in the construction (yes, this is done explicitly at the end.)
[x] idea for the numeric literals: construct them on demand in special cases, or start with very large pool of them if pruning goes quickly
[x] shouldn't we be seeing constructions of circles with a named radius? # This command exists, so we should sometimes.
[x] deleted the product commands for diversity, also removed a few other commands
[x] handled Union types and removed them from the set of commands.
[x] count num_ancestors in graph so that ones with high ancestors can be used
[x] keep track of types of things in graph so we can know to measure a measurable thing
[x] handle polygon() specially
[x] implement the algorithm that actually finds measurable nodes with a lot of ancestors. 


refactor:
[x] make sure retvals are handled in a sensible way.
[x] make sure that the return to sample_command is a sensible type.
[x] factor out the sampling logic so that can later be overridden.
[x] solve the polygon special case again.
[x] need to see if Element class or similar contains most of the logic for what we need for Node, or if Node can simply hold Element to reduce complexity.
[x] look at is_compatible_type(). is it still necessary? can't we just check type directly? only confusion is int and float, and generating new constants on the fly. this is already a bug.

- most ancestors calculation is currently heuristic. also, in general it is not clear that it gives you the characteristics that generate good constructions.
- generator does a bunch of work at initialization time. if too slow, measure it to reduce overhead.

- i think we want something slightly more sophisticated-- we want to measure something that requires a longer deduction at the end.
- *how do we ensure that most of the commands in the construction are actually necessary?* -- I think it should be possible to automatically prune unused commands from the construction.
  - note this may be achievable with a dependency graph; note this may not be strictly necessary because the pruning algorithm might be pretty easy.
- starting heuristics, constructing points and defining one numeric literal are too rigid. but i think good enough for now until other more obvious issues are solved.
